{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b4e9ea",
   "metadata": {},
   "source": [
    "# Load Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578142ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.python.keras.layers import MaxPooling2D, Dropout, Flatten, Dense, Conv2D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.saving.save import load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable gpu if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83504d0",
   "metadata": {},
   "source": [
    "# Image and sample size\n",
    "Images will be resized to `img_rows` and `img_cols`.\n",
    "We will try to classify images\n",
    "- Ransomwares\n",
    "- Legits\n",
    "Each class contains `sample_size` examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b45341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 300, 300\n",
    "sample_size = 3316"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6faff07",
   "metadata": {},
   "source": [
    "We load images in x (dimensions : `(img_rows, img_cols, 1)`) and labels in y (`True` : Ransomware ; `False` : Legit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb9b94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples: 3316, negative examples: 3316\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "dirs = [r'Data/Ransomware_Img', r'Data/Legit_Img']\n",
    "\n",
    "is_ransomware = 1\n",
    "for dir in dirs:\n",
    "    idx = 0\n",
    "    for fimg in os.listdir(dir):\n",
    "        if idx < sample_size:\n",
    "            path_fimg = os.path.join(dir, fimg)\n",
    "            if fimg.endswith('checkpoints') == False and os.path.getsize(path_fimg) > 1:\n",
    "                image = Image.open(path_fimg)\n",
    "                img = image.resize((img_rows, img_cols))\n",
    "                image.close()\n",
    "                if img.size[0] == img_rows:\n",
    "                    data = np.array(img, dtype='uint8')\n",
    "                    x.append(data)\n",
    "                    y.append(is_ransomware == 1)\n",
    "            idx += 1\n",
    "    is_ransomware -= 1\n",
    "\n",
    "x = numpy.array(x)\n",
    "y = numpy.array(y)\n",
    "print(f'Positive examples: {sum(y)}, negative examples: {len(y)-sum(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6071e92",
   "metadata": {},
   "source": [
    "Split values between Train and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077aa02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=42, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370937b",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "We only have to center and scale: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72fa989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "596880136\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "print(sys.getsizeof(scaler))\n",
    "print(sys.getsizeof(x, y))\n",
    "scaler.fit_transform(x_train.reshape((x_train.shape[0], img_rows*img_cols)))\n",
    "scaler.transform(x_val.reshape((x_val.shape[0], img_rows*img_cols)))\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], img_rows, img_cols, 1))\n",
    "x_val = x_val.reshape((x_val.shape[0], img_rows, img_cols, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f62914",
   "metadata": {},
   "source": [
    "# Training\n",
    "We're in a two classes classification problem for which we can use a sigmoid output upon a binary crossentropy error optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ea1b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 15:47:18.792243: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-29 15:47:18.792293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-16-4-167.eu-west-3.compute.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-07-29 15:47:18.792909: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 296, 296, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               89719296  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 89,983,297\n",
      "Trainable params: 89,983,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (5, 5), data_format='channels_last',\n",
    "                 activation = 'relu', input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(MaxPooling2D(pool_size = (4, 4), data_format='channels_last'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\",\n",
    "              optimizer = 'rmsprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a250ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999 0.9999999999999999\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 15:47:21.060072: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1435500544 exceeds 10% of free system memory.\n",
      "2022-07-29 15:47:25.686484: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1435500544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/39 [..............................] - ETA: 6:13 - loss: 15.5631 - accuracy: 0.5469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 15:47:30.036477: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1435500544 exceeds 10% of free system memory.\n",
      "2022-07-29 15:47:34.700615: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1435500544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/39 [>.............................] - ETA: 5:35 - loss: 3873.4104 - accuracy: 0.5156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 15:47:39.096140: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1435500544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 384s 10s/step - loss: 1316.5299 - accuracy: 0.5561 - val_loss: 8.5068 - val_accuracy: 0.5555\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 382s 10s/step - loss: 3.8172 - accuracy: 0.5696 - val_loss: 0.6736 - val_accuracy: 0.5217\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 383s 10s/step - loss: 1.2749 - accuracy: 0.5078 - val_loss: 0.6882 - val_accuracy: 0.4994\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 381s 10s/step - loss: 2.9646 - accuracy: 0.5287 - val_loss: 2.3877 - val_accuracy: 0.6062\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 379s 10s/step - loss: 1.2316 - accuracy: 0.6184 - val_loss: 0.5900 - val_accuracy: 0.6900\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 379s 10s/step - loss: 1.0444 - accuracy: 0.6779 - val_loss: 0.6259 - val_accuracy: 0.7376\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 377s 10s/step - loss: 1.1514 - accuracy: 0.7447 - val_loss: 0.4970 - val_accuracy: 0.7961\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 376s 10s/step - loss: 0.6869 - accuracy: 0.7720 - val_loss: 0.6336 - val_accuracy: 0.7931\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 376s 10s/step - loss: 0.6450 - accuracy: 0.8060 - val_loss: 0.3772 - val_accuracy: 0.8353\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 376s 10s/step - loss: 0.5019 - accuracy: 0.8239 - val_loss: 0.4841 - val_accuracy: 0.7967\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 377s 10s/step - loss: 0.4567 - accuracy: 0.8484 - val_loss: 0.4821 - val_accuracy: 0.8396\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 376s 10s/step - loss: 0.3518 - accuracy: 0.8890 - val_loss: 0.4571 - val_accuracy: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d519aea30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(y)\n",
    "weight_for_0 = (1 / (len(y)-sum(y))) * (total / 2.0)\n",
    "weight_for_1 = (1 / sum(y)) * (total / 2.0)\n",
    "print(weight_for_0, weight_for_1)\n",
    "\n",
    "model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = 128,\n",
    "        epochs = 100,\n",
    "        verbose = 1,\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1},\n",
    "        callbacks = [EarlyStopping(monitor = 'val_loss', patience = 3, restore_best_weights = True)],\n",
    "        validation_data = (x_val, y_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940893d3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e82c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3772081136703491\n",
      "Test accuracy: 0.8353437781333923\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.90      0.84       810\n",
      "        True       0.89      0.77      0.83       848\n",
      "\n",
      "    accuracy                           0.84      1658\n",
      "   macro avg       0.84      0.84      0.84      1658\n",
      "weighted avg       0.84      0.84      0.83      1658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(x_val)\n",
    "y_pred = [ (e > 0.5) for e in y]\n",
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607be7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
